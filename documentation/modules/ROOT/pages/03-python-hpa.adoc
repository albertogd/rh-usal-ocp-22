= Autoscaling based on Memory utilization

In this exercise, you will create a Python application to simulate Memory load to test application autoscaling using Horizontal Pod Autoscaler.

[#applications]
== Create a Python applications

1) Create a Python applications using S2I and expose the applications.

Python application:

* Name: stress-python
* Repo: https://github.com/albertogd/rh-usal-ocp-22.git
* Branch: master
* Path: apps/hpa/stress-python

[source,bash,subs="+macros,+attributes"]
----
$ oc new-app https://github.com/albertogd/rh-usal-ocp-22.git --context-dir apps/hpa/stress-python --name stress-python
$ oc expose svc/stress-python
----

[#requests]
== Configure requests and limits

2) Configure the applications with a request of cpu = 200m and memory = 200M, and a limit of cpu = 400m and memory = 200M.

[source,bash,subs="+macros,+attributes"]
----
$ oc set resources deployment/stress-python --requests=cpu=200m,memory=200M --limits=cpu=400m,memory=400M
----

Check the requests and limits configured:

[source,bash,subs="+macros,+attributes"]
----
$ oc describe deployment/stress-python | grep -A2 "Request\|Limit"
    Limits:
      cpu:     400m
      memory:  400M
    Requests:
      cpu:        200m
      memory:     200M
----

As default route timeout is 30 seconds, add an annotation to the route to increase timeout to 5 min.

[source,bash,subs="+macros,+attributes"]
----
$ oc annotate route stress-python haproxy.router.openshift.io/timeout=300s --overwrite
----

[#memory]
== Autoscaling based on Memory utilization

3) In this part you’ll test test autoscale using memory metrics. This feature is TP in Openshift, and unlike CPU-based autoscaling, memory-based autoscaling requires specifying the autoscaler using YAML instead of using the oc autoscale command.

Create the HPA oc apply -f <file> with this manifest:

[source,yaml,subs="+macros,+attributes"]
----
apiVersion: autoscaling/v2beta2 
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-test-memory 
spec:
  scaleTargetRef:
    apiVersion: apps/v1 
    kind: Deployment 
    name: stress-python
  minReplicas: 1 
  maxReplicas: 10 
  metrics: 
  - type: Resource
    resource:
      name: memory 
      target:
        type: Utilization 
        averageUtilization: 50
----

The Python app has an endpoint /memory/200/2.
Get the application route, and make a request of 200 MB for 2 minute. After 2 minutes, you’ll receive an empty reply from the server (you can also run in the background the curl).

[source,bash,subs="+macros,+attributes"]
----
$ curl http://$(oc get route stress-python -o json | jq -r '.spec.host')/memory/200/2
----

In another terminal, check with PodMetrics the current CPU load, the hpa and the number of pods.

[source,bash,subs="+macros,+attributes"]
----
$ oc get podMetrics
NAME                          CPU   MEMORY    WINDOW
stress-python-7799f7d976-dh5wl   1m    34856Ki   5m0s

$ oc get hpa
NAME              REFERENCE             TARGETS                 MINPODS   MAXPODS   REPLICAS   AGE
hpa-test-memory   Deployment/test-hpa   120%/50%       1                     10                    3                11m

$ oc get pods  --field-selector status.phase=Running -o name | wc -l
3
----

Make a request of 500 MB for 2 minute. Can you explain what’s happening now and what’s the difference before and now?

[source,bash,subs="+macros,+attributes"]
----
$ curl http://$(oc get route stress-python -o json | jq -r '.spec.host')/memory/500/2
<html><body><h1>502 Bad Gateway</h1>
The server returned an invalid or incomplete response.
</body></html>
----

====
We configured a Memory limit of 400M, so when the application tried to use 500M, it failed. We get an error from the application.

Before we had a Utilization of 50%, and the memory request of the POD was 200M. As we did a request of 200M, plus the 20 MB that the container uses, we used around 220M. 220/100 is a target of 120%,  so the hpa added 2 more replicas:

[cols="^60%,^40%" width="40%"]
|===
|TARGET|PODS 

|0-49% / 50%
|1

|50%-99% / 50%
|2

|100% - 149% / 50%
|3
|===

====
